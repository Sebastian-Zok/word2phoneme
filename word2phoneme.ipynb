{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0222e89b-ffcc-4afe-b352-ecd474489562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Activation, Dropout\n",
    "from keras.layers import  Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb867b58-0b17-4f4c-9d06-7fa0112ab24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei lesen\n",
    "file_path = './cmudict.txt'\n",
    "\n",
    "# Listen für Wörter und Phoneme\n",
    "words = []\n",
    "phonemes = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Trennen des Wortes und der Phoneme beim ersten Leerzeichen\n",
    "        word, phoneme_string = line.strip().split(' ', 1)\n",
    "        word = re.sub(r'\\(.*?\\)', '', word)\n",
    "        \n",
    "        # Überprüfen, ob das Wort unerwünschte Zeichen enthält\n",
    "        if re.search(r'[\\d_\\-ÀÉ]', word):\n",
    "            continue\n",
    "        \n",
    "        phoneme_list = phoneme_string.split()\n",
    "        # Entfernen der Betonungszahlen aus den Phonemen\n",
    "        cleaned_phonemes = [re.sub(r'\\d', '', phoneme) for phoneme in phoneme_list]\n",
    "        words.append(word)\n",
    "        phonemes.append(' '.join(cleaned_phonemes))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cfdaf28b-aec4-446b-b0e9-b4ae62e35d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisierung der Wörter und Phoneme\n",
    "word_encoder = LabelEncoder()\n",
    "phoneme_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "645962c3-3c42-4a09-9575-f5974f259734",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = list(set(''.join(words)))\n",
    "all_phonemes = list(set(' '.join(phonemes).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a77f61c-66c2-4910-9795-8e8941ebe7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K',\n",
       " 'Y',\n",
       " 'W',\n",
       " 'O',\n",
       " 'T',\n",
       " 'Q',\n",
       " 'J',\n",
       " 'H',\n",
       " 'S',\n",
       " 'Z',\n",
       " 'U',\n",
       " \"'\",\n",
       " 'A',\n",
       " 'G',\n",
       " 'P',\n",
       " 'R',\n",
       " 'X',\n",
       " '.',\n",
       " 'B',\n",
       " 'F',\n",
       " 'V',\n",
       " 'L',\n",
       " 'N',\n",
       " 'E',\n",
       " 'D',\n",
       " 'M',\n",
       " 'C',\n",
       " 'I']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ccc7f4f-8c84-4624-bbe5-13e47a908f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_encoder.fit(all_chars)\n",
    "phoneme_encoder.fit(all_phonemes)\n",
    "\n",
    "encoded_words = [word_encoder.transform(list(word)) for word in words]\n",
    "encoded_phonemes = [phoneme_encoder.transform(phoneme.split()) for phoneme in phonemes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6191573b-da5d-4ad8-8d64-4151dca16ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der verschiedenen Zeichen und Phoneme\n",
    "num_chars = len(word_encoder.classes_)\n",
    "num_phonemes = len(phoneme_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf027ea7-8c73-4505-940b-58c3445b3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding der Sequenzen\n",
    "max_word_length = max(len(word) for word in encoded_words)\n",
    "max_phoneme_length = max(len(phoneme) for phoneme in encoded_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3e11bee1-b9eb-42df-a275-a4415ee2b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding der Sequenzen\n",
    "max_length = max(max_word_length, max_phoneme_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "def72815-7f91-4af3-9edf-f05050c3307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Woerter mit Padding versehen\n",
    "padded_words = pad_sequences(encoded_words, maxlen=max_length, padding='post')\n",
    "padded_phonemes = pad_sequences(encoded_phonemes, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a787c23-0c2c-4523-95f6-1c200aba5fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_14                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_15                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_11 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_14 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_15 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_14                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_15                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_11 (\u001b[38;5;33mActivation\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modellaufbau\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(word_encoder.classes_), output_dim=64))\n",
    "\n",
    "    # Erste LSTM-Schicht mit Dropout\n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    \n",
    "    # Zweite LSTM-Schicht mit Dropout\n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    \n",
    "    # Dense-Schicht mit L2-Regularisierung\n",
    "    model.add(TimeDistributed(Dense(128, activation='relu', kernel_regularizer=l2(0.01))))\n",
    "    \n",
    " \n",
    "    # Ausgabe-Schicht\n",
    "    model.add(TimeDistributed(Dense(len(phoneme_encoder.classes_))))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=[masked_accuracy])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Modellzusammenfassung\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5d2704c8-810a-41e2-82b5-41ed0af6c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umwandeln der Labels für das Training aka verschachteln der werte in einzelne arrays\n",
    "y = np.expand_dims(padded_phonemes, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8e44e93-8f6d-43a9-9bb2-e57cdf77718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Eager Execution aktivieren\n",
    "tf.config.run_functions_eagerly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96ce1fe5-c6cd-480a-becf-bc89e0bacdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(y_true, y_pred):\n",
    "   # Konvertiere Vorhersagen in Klassen\n",
    "    y_pred_class = tf.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    # Entferne die letzte Dimension von y_true\n",
    "    y_true = tf.squeeze(y_true, -1)\n",
    "    \n",
    "    # Maskiere die gepolsterten Werte (Annahmen: 0 ist der gepolsterte Wert)\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype=tf.float32)\n",
    "    \n",
    "    # Korrekte Vorhersagen\n",
    "    matches = tf.cast(tf.equal(y_true, tf.cast(y_pred_class, y_true.dtype)), dtype=tf.float32)\n",
    "    \n",
    "    # Anzahl der korrekten Vorhersagen (ohne Padding)\n",
    "    masked_matches = tf.reduce_sum(matches * mask)\n",
    "    \n",
    "    # Anzahl der gültigen Datenpunkte (ohne Padding)\n",
    "    masked_count = tf.reduce_sum(mask)\n",
    "    \n",
    "    # Berechnung der Genauigkeit\n",
    "    return masked_matches / masked_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b456d8d-68a0-4393-87e5-542646f4ca37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "43fda5d4-e452-4603-8017-8c6f22e69d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 114ms/step - loss: 0.6761 - masked_accuracy: 0.2766 - val_loss: 0.2388 - val_masked_accuracy: 0.6946\n",
      "Epoch 2/5\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 114ms/step - loss: 0.1950 - masked_accuracy: 0.7595 - val_loss: 0.1767 - val_masked_accuracy: 0.7924\n",
      "Epoch 3/5\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 117ms/step - loss: 0.1502 - masked_accuracy: 0.8155 - val_loss: 0.1566 - val_masked_accuracy: 0.8089\n",
      "Epoch 4/5\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 117ms/step - loss: 0.1314 - masked_accuracy: 0.8390 - val_loss: 0.1519 - val_masked_accuracy: 0.8224\n",
      "Epoch 5/5\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 118ms/step - loss: 0.1215 - masked_accuracy: 0.8507 - val_loss: 0.1447 - val_masked_accuracy: 0.8242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2be51eeb8e0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_words, y, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43c65363-ba78-40f3-bc1a-1c845da43757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Desktop\\text2phone\\.text2phone\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:102: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  return saving_lib.save_model(model, filepath)\n"
     ]
    }
   ],
   "source": [
    "# Modell speichern\n",
    "model.save('word_to_phoneme_model_nostress_new.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6557d478-2562-4673-a80c-ffabe7f8cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_phonemes(word):\n",
    "    word = re.sub(r'\\(.*?\\)', '', word)\n",
    "    encoded_word = word_encoder.transform(list(word))\n",
    "    padded_word = pad_sequences([encoded_word], max_length, padding=\"post\")\n",
    "    prediction = model.predict(padded_word)\n",
    "    predicted_phonemes = np.argmax(prediction, axis=-1)\n",
    "    return phoneme_encoder.inverse_transform(predicted_phonemes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d43c6029-d3b0-4ecc-9915-f06e3179de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
      "Z AY G ER AA N IH AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "M AE S AH CH UW S IH Z S AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "S EY B AE S CH AH N AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "F AH L L IY EH AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "F AH K AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "IY Z IH P IY AH IY AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA AA\n"
     ]
    }
   ],
   "source": [
    "new_word = \"ZEIGARNIK\"\n",
    "predicted_phonemes = predict_phonemes(new_word)\n",
    "print(\" \".join(predicted_phonemes))\n",
    "new_word = \"MASSACHUSETTS\"\n",
    "predicted_phonemes = predict_phonemes(new_word)\n",
    "print(\" \".join(predicted_phonemes))\n",
    "new_word = \"SEBASTIAN\"\n",
    "predicted_phonemes = predict_phonemes(new_word)\n",
    "print(\" \".join(predicted_phonemes))\n",
    "new_word = \"FML\"\n",
    "predicted_phonemes = predict_phonemes(new_word)\n",
    "print(\" \".join(predicted_phonemes))\n",
    "new_word = \"FUCK\"\n",
    "predicted_phonemes = predict_phonemes(new_word)\n",
    "print(\" \".join(predicted_phonemes))\n",
    "new_word = \"EASYPIEZY\"\n",
    "predicted_phonemes = predict_phonemes(new_word)\n",
    "print(\" \".join(predicted_phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7464c2a8-1c11-498d-bd18-ee3300aa0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"word_to_phoneme_model_masking.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ea619-1816-46d8-ba9d-3836bdc0c06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
