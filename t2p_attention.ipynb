{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0190c3a8-88f8-4a8b-8846-fc2c6a43158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "words = []\n",
    "phonemes = []\n",
    "\n",
    "# Datei lesen\n",
    "file_path = './cmudict.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Trennen des Wortes und der Phoneme beim ersten Leerzeichen\n",
    "        word, phoneme_string = line.strip().split(' ', 1)\n",
    "        word = re.sub(r'\\(.*?\\)', '', word)\n",
    "        \n",
    "        # Überprüfen, ob das Wort unerwünschte Zeichen enthält\n",
    "        if re.search(r'[\\d_\\-ÀÉ]', word):\n",
    "            continue\n",
    "        \n",
    "        phoneme_list = phoneme_string.split()\n",
    "        # Entfernen der Betonungszahlen aus den Phonemen\n",
    "        cleaned_phonemes = [re.sub(r'\\d', '', phoneme) for phoneme in phoneme_list]\n",
    "        words.append(word)\n",
    "        phonemes.append(' '.join(cleaned_phonemes).split(' '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc83a6b5-d653-4181-8b64-97a2f51b0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = list(set(''.join(words)))\n",
    "all_phonemes = list(set(' '.join([' '.join(phoneme) for phoneme in phonemes]).split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ad5aebc-218b-4bdb-9931-6389bcc7a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_phonemes(phoneme_list, encoder):\n",
    "    # Encode each list of phonemes\n",
    "    encoded_phonemes = [encoder.transform(phoneme) for phoneme in phoneme_list]\n",
    "    return encoded_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59d33e54-3e7f-4af5-af63-415faedb13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tokenisierung der Wörter und Phoneme\n",
    "word_encoder = LabelEncoder()\n",
    "phoneme_encoder = LabelEncoder()\n",
    "\n",
    "word_encoder.fit(all_chars)\n",
    "phoneme_encoder.fit(all_phonemes)\n",
    "\n",
    "# Anzahl der verschiedenen Zeichen und Phoneme\n",
    "num_chars = len(word_encoder.classes_)\n",
    "num_phonemes = len(phoneme_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9335a88-db02-4266-aacd-4fa2f1cfa7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_words = [word_encoder.transform(list(word)) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b762bfe-f01f-46f5-bcd0-2baad834f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_phonemes = encode_phonemes(phonemes, phoneme_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b0bf359-131a-4021-900b-e6b6e9a43351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = max(max(len(seq) for seq in encoded_words), max(len(seq) for seq in encoded_phonemes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0904dec7-e12b-4486-b50c-ba5b15f137c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = pad_sequences(encoded_words, maxlen=max_len, padding='post')\n",
    "y_padded = pad_sequences(encoded_phonemes, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b328e298-885e-43b2-9767-56a0d4ad0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def masked_accuracy(y_true, y_pred):\n",
    "   # Konvertiere Vorhersagen in Klassen\n",
    "    y_pred_class = tf.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    # Entferne die letzte Dimension von y_true\n",
    "    y_true = tf.squeeze(y_true, -1)\n",
    "    \n",
    "    # Maskiere die gepolsterten Werte (Annahmen: 0 ist der gepolsterte Wert)\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype=tf.float32)\n",
    "    \n",
    "    # Korrekte Vorhersagen\n",
    "    matches = tf.cast(tf.equal(y_true, tf.cast(y_pred_class, y_true.dtype)), dtype=tf.float32)\n",
    "    \n",
    "    # Anzahl der korrekten Vorhersagen (ohne Padding)\n",
    "    masked_matches = tf.reduce_sum(matches * mask)\n",
    "    \n",
    "    # Anzahl der gültigen Datenpunkte (ohne Padding)\n",
    "    masked_count = tf.reduce_sum(mask)\n",
    "    \n",
    "    # Berechnung der Genauigkeit\n",
    "    return masked_matches / masked_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f6e01642-f10f-425c-bbce-832db3acb86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_8               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,363,392</span> │ embedding_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                               │                           │                 │ bidirectional_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ bidirectional_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ time_distributed_8            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">39,975</span> │ dot_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)             │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m1,792\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_8               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │       \u001b[38;5;34m2,363,392\u001b[0m │ embedding_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_12 (\u001b[38;5;33mDot\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ bidirectional_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                               │                           │                 │ bidirectional_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ dot_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dot_13 (\u001b[38;5;33mDot\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ bidirectional_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ time_distributed_8            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m39\u001b[0m)            │          \u001b[38;5;34m39,975\u001b[0m │ dot_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)             │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,405,159</span> (9.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,405,159\u001b[0m (9.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,405,159</span> (9.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,405,159\u001b[0m (9.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, Bidirectional, Dot, Activation\n",
    "from tensorflow.keras.layers import Attention\n",
    "\n",
    "input_seq = Input(shape=(max_len,))\n",
    "embedded_seq = Embedding(input_dim=num_chars, output_dim=64)(input_seq)\n",
    "lstm_seq = Bidirectional(LSTM(512, return_sequences=True))(embedded_seq)\n",
    "\n",
    "# Berechnung der Attention-Gewichte\n",
    "attention_scores = Dot(axes=[2, 2])([lstm_seq, lstm_seq])\n",
    "attention_weights = Activation('softmax')(attention_scores)\n",
    "\n",
    "# Apply the attention weights to the LSTM output\n",
    "context_vector = Dot(axes=[2, 1])([attention_weights, lstm_seq])\n",
    "\n",
    "output_seq = TimeDistributed(Dense(num_phonemes, activation='softmax'))(context_vector)\n",
    "\n",
    "model = Model(inputs=input_seq, outputs=output_seq)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[masked_accuracy])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a599b8f3-6630-4cd7-92b8-423ba345f32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 118ms/step - loss: 0.4769 - masked_accuracy: 0.3700 - val_loss: 0.1747 - val_masked_accuracy: 0.7394\n",
      "Epoch 2/4\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 117ms/step - loss: 0.1350 - masked_accuracy: 0.8024 - val_loss: 0.1404 - val_masked_accuracy: 0.8013\n",
      "Epoch 3/4\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 118ms/step - loss: 0.1022 - masked_accuracy: 0.8481 - val_loss: 0.1295 - val_masked_accuracy: 0.8139\n",
      "Epoch 4/4\n",
      "\u001b[1m3331/3331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 118ms/step - loss: 0.0871 - masked_accuracy: 0.8693 - val_loss: 0.1284 - val_masked_accuracy: 0.8157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f8c9e42e30>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_paddeds = np.array(X_padded)\n",
    "y_paddeds = np.expand_dims(np.array(y_padded), -1)\n",
    "\n",
    "model.fit(X_paddeds, y_paddeds, epochs=4, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d56f471d-902a-46d5-87e5-4ccb448e6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage und Attention-Gewichte extrahieren\n",
    "attention_extractor = Model(inputs=model.input, outputs=[output_seq, attention_weights])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1eaa8377-f5a6-43af-a284-4c2bce0e0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Word: ITWORKS\n",
      "  Predicted Phoneme:  ['IH']\n",
      "  Attention Weights:\n",
      "    Grapheme: I -> Weight: 0.9997\n",
      "    Grapheme: T -> Weight: 0.0003\n",
      "    Grapheme: W -> Weight: 0.0000\n",
      "    Grapheme: O -> Weight: 0.0000\n",
      "    Grapheme: R -> Weight: 0.0000\n",
      "    Grapheme: K -> Weight: 0.0000\n",
      "    Grapheme: S -> Weight: 0.0000\n",
      "  Predicted Phoneme:  ['T']\n",
      "  Attention Weights:\n",
      "    Grapheme: I -> Weight: 0.0000\n",
      "    Grapheme: T -> Weight: 1.0000\n",
      "    Grapheme: W -> Weight: 0.0000\n",
      "    Grapheme: O -> Weight: 0.0000\n",
      "    Grapheme: R -> Weight: 0.0000\n",
      "    Grapheme: K -> Weight: 0.0000\n",
      "    Grapheme: S -> Weight: 0.0000\n",
      "  Predicted Phoneme:  ['W']\n",
      "  Attention Weights:\n",
      "    Grapheme: I -> Weight: 0.0000\n",
      "    Grapheme: T -> Weight: 0.0000\n",
      "    Grapheme: W -> Weight: 1.0000\n",
      "    Grapheme: O -> Weight: 0.0000\n",
      "    Grapheme: R -> Weight: 0.0000\n",
      "    Grapheme: K -> Weight: 0.0000\n",
      "    Grapheme: S -> Weight: 0.0000\n",
      "  Predicted Phoneme:  ['ER']\n",
      "  Attention Weights:\n",
      "    Grapheme: I -> Weight: 0.0000\n",
      "    Grapheme: T -> Weight: 0.0000\n",
      "    Grapheme: W -> Weight: 0.0000\n",
      "    Grapheme: O -> Weight: 0.9988\n",
      "    Grapheme: R -> Weight: 0.0011\n",
      "    Grapheme: K -> Weight: 0.0000\n",
      "    Grapheme: S -> Weight: 0.0000\n",
      "  Predicted Phoneme:  ['K']\n",
      "  Attention Weights:\n",
      "    Grapheme: I -> Weight: 0.0000\n",
      "    Grapheme: T -> Weight: 0.0000\n",
      "    Grapheme: W -> Weight: 0.0000\n",
      "    Grapheme: O -> Weight: 0.0000\n",
      "    Grapheme: R -> Weight: 0.6724\n",
      "    Grapheme: K -> Weight: 0.3275\n",
      "    Grapheme: S -> Weight: 0.0001\n",
      "  Predicted Phoneme:  ['S']\n",
      "  Attention Weights:\n",
      "    Grapheme: I -> Weight: 0.0000\n",
      "    Grapheme: T -> Weight: 0.0000\n",
      "    Grapheme: W -> Weight: 0.0000\n",
      "    Grapheme: O -> Weight: 0.0000\n",
      "    Grapheme: R -> Weight: 0.0000\n",
      "    Grapheme: K -> Weight: 0.7060\n",
      "    Grapheme: S -> Weight: 0.2936\n"
     ]
    }
   ],
   "source": [
    "word = [\"ITWORKS\"]\n",
    "\n",
    "query = np.array(pad_sequences([word_encoder.transform(list(word[0]))], maxlen=max_len, padding='post'))\n",
    "attention_weights = attention_layer_model.predict(query)\n",
    "\n",
    "# Vorhersage der Phoneme\n",
    "prediction = model.predict(query)\n",
    "predicted_phonemes = np.argmax(prediction, axis=-1)\n",
    "phoneme_res = phoneme_encoder.inverse_transform(predicted_phonemes[0])\n",
    "\n",
    "# Analyse der Attention-Gewichte und Vorhersagen\n",
    "for i, (word, pred) in enumerate(zip(word, prediction)):\n",
    "    print(f\"Word: {word}\")\n",
    "    for j, phoneme_id in enumerate(np.argmax(pred, axis=-1)):\n",
    "        if phoneme_id != 0:\n",
    "            print(f\"  Predicted Phoneme:  {phoneme_encoder.inverse_transform([phoneme_id])}\")\n",
    "            print(\"  Attention Weights:\")\n",
    "            for k, weight in enumerate(attention_weights[0][j]):\n",
    "                if k < len(word):\n",
    "                    print(f\"    Grapheme: {word[k]} -> Weight: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ba32d-8b8e-46d4-a0d2-ccaf440d4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Konvertiere die Vorhersagen zurück zu Phonemen\n",
    "id_to_phoneme = {idx: phoneme for phoneme, idx in phoneme_to_id.items()}\n",
    "\n",
    "# Analyse der Attention-Gewichte und Vorhersagen\n",
    "for i, (word, pred) in enumerate(zip(words, predictions)):\n",
    "    print(f\"Word: {word}\")\n",
    "    for j, phoneme_id in enumerate(np.argmax(pred, axis=-1)):\n",
    "        if phoneme_id != 0:\n",
    "            print(f\"  Predicted Phoneme: {id_to_phoneme[phoneme_id]}\")\n",
    "            print(\"  Attention Weights:\")\n",
    "            for k, weight in enumerate(attention_weights[i][j]):\n",
    "                if k < len(word):\n",
    "                    print(f\"    Grapheme: {word[k]} -> Weight: {weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ba31cd51-e5d5-4036-952b-79ae5e0a08c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37,  5, 14, 22, 22, 16], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_phonemes[predicted_phonemes != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8489ca80-bfdc-4744-bc0a-9e41831e4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell speichern\n",
    "model.save('word_to_phoneme_model_ATTENTION_10MB.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
